{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN Training Pipeline\n",
    "This notebook trains a simple CNN on the MNIST dataset, then saves the model weights for later FPGA integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# (Optional) Fix seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dataset Preparation\n",
    "transform = transforms.ToTensor()\n",
    "mnist_train = datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='../data', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistCNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1568, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from mnist_model import MnistCNN\n",
    "# Instantiate model\n",
    "model = MnistCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "# Track best model\n",
    "best_accuracy = 0.0\n",
    "best_model_wts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.2312, Accuracy: 0.9298\n",
      "Epoch 2/10 - Loss: 0.0628, Accuracy: 0.9806\n",
      "Epoch 3/10 - Loss: 0.0438, Accuracy: 0.9864\n",
      "Epoch 4/10 - Loss: 0.0342, Accuracy: 0.9896\n",
      "Epoch 5/10 - Loss: 0.0275, Accuracy: 0.9911\n",
      "Epoch 6/10 - Loss: 0.0215, Accuracy: 0.9930\n",
      "Epoch 7/10 - Loss: 0.0179, Accuracy: 0.9941\n",
      "Epoch 8/10 - Loss: 0.0128, Accuracy: 0.9960\n",
      "Epoch 9/10 - Loss: 0.0118, Accuracy: 0.9961\n",
      "Epoch 10/10 - Loss: 0.0109, Accuracy: 0.9964\n"
     ]
    }
   ],
   "source": [
    "# 5. Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "# 6. Evaluation on Test Set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "test_acc = correct / total\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to ../model/best_mnist_cnn.pth\n"
     ]
    }
   ],
   "source": [
    "# 7. Saving the Model Weights\n",
    "torch.save(model.state_dict(), '../model/best_mnist_cnn.pth')\n",
    "print('Model weights saved to ../model/best_mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Export for FPGA, Quantization, Reference Inference\n",
    "- Quantize and export weights as needed\n",
    "- Run sample inference and compare outputs\n",
    "- Document accuracy and training details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved conv1.weight to ../../weights/conv1_weight.hex\n",
      "Saved conv1.bias to ../../weights/conv1_bias.hex\n",
      "Saved conv2.weight to ../../weights/conv2_weight.hex\n",
      "Saved conv2.bias to ../../weights/conv2_bias.hex\n",
      "Saved fc1.weight to ../../weights/fc1_weight.hex\n",
      "Saved fc1.bias to ../../weights/fc1_bias.hex\n",
      "Saved fc2.weight to ../../weights/fc2_weight.hex\n",
      "Saved fc2.bias to ../../weights/fc2_bias.hex\n",
      "Saved requant params to ../../weights/requant_params.json\n"
     ]
    }
   ],
   "source": [
    "from quantize import quantize_model_weights\n",
    "from convert_to_hex import save_model_weights_hex\n",
    "\n",
    "model = MnistCNN()\n",
    "model.load_state_dict(torch.load(\"../model/best_mnist_cnn.pth\"))\n",
    "model.eval()\n",
    "\n",
    "quantized_params = quantize_model_weights(model, num_bits=8, bias_bits=32)\n",
    "save_model_weights_hex(quantized_params, base_path=\"../../weights/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../images/test_img_0000_label7.hex\n",
      "Saved ../../images/test_img_0001_label2.hex\n",
      "Saved ../../images/test_img_0002_label1.hex\n",
      "Saved ../../images/test_img_0003_label0.hex\n",
      "Saved ../../images/test_img_0004_label4.hex\n",
      "Saved ../../images/test_img_0005_label1.hex\n",
      "Saved ../../images/test_img_0006_label4.hex\n",
      "Saved ../../images/test_img_0007_label9.hex\n",
      "Saved ../../images/test_img_0008_label5.hex\n",
      "Saved ../../images/test_img_0009_label9.hex\n"
     ]
    }
   ],
   "source": [
    "# 8. Save MNIST test images to hex files for FPGA image_streamer\n",
    "\n",
    "import os\n",
    "\n",
    "def save_mnist_hex(image_tensor, filename):\n",
    "    \"\"\"\n",
    "    Save a single MNIST image tensor (1x28x28) as a .hex file.\n",
    "    Each line contains one pixel in 2-digit hex (00â€“FF).\n",
    "    \"\"\"\n",
    "    img = (image_tensor.squeeze() * 255).to(torch.uint8).numpy()  # shape (28,28)\n",
    "    with open(filename, \"w\") as f:\n",
    "        for y in range(28):\n",
    "            for x in range(28):\n",
    "                pixel = int(img[y, x])\n",
    "                f.write(f\"{pixel:02x}\\n\")\n",
    "\n",
    "# Directory for saving test images\n",
    "img_out_dir = \"../../images/\"\n",
    "os.makedirs(img_out_dir, exist_ok=True)\n",
    "\n",
    "# Save the first N test images\n",
    "N = 10\n",
    "for i in range(N):\n",
    "    img, label = mnist_test[i]  # (1,28,28), label\n",
    "    out_file = os.path.join(img_out_dir, f\"test_img_{i:04d}_label{label}.hex\")\n",
    "    save_mnist_hex(img, out_file)\n",
    "    print(f\"Saved {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../../weights/requant_params.json\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "layers = [\"conv1.bias\", \"conv2.bias\", \"fc1.bias\", \"fc2.bias\"]\n",
    "\n",
    "with open(\"../../weights/requant_params.hex\", \"w\") as f:\n",
    "    for l in layers:\n",
    "        scale = params[l][\"scale_int\"]\n",
    "        shift = params[l][\"shift\"]\n",
    "        # pack scale and shift in one 32-bit word: [31:16]=scale, [15:0]=shift\n",
    "        word = (scale << 16) | (shift & 0xFFFF)\n",
    "        f.write(f\"{word:08x}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
